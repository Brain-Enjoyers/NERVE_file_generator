{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc4f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install snntorch --quiet\n",
    "# pip install nir --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5bb1b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import nir\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e433c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/tmp/data/mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef52175-75cc-4d3c-babe-84fee3d3cf24",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Plotting Settings\n",
    "def plot_mem(mem, ymin=-200, ymax=50, xmax=25, title=False):\n",
    "  if title:\n",
    "    plt.title(title)\n",
    "  plt.plot(mem, 'bo')\n",
    "  plt.xlabel(\"Time step\")\n",
    "  plt.ylabel(\"Membrane Potential\")\n",
    "  plt.xlim([0, xmax])\n",
    "  plt.ylim([ymin,ymax])\n",
    "  plt.show()\n",
    "\n",
    "def plot_step_current_response(cur_in, mem_rec, vline1):\n",
    "  fig, ax = plt.subplots(2, figsize=(8,6),sharex=True)\n",
    "\n",
    "  # Plot input current\n",
    "  ax[0].plot(cur_in, c=\"tab:orange\")\n",
    "  ax[0].set_ylim([0, 0.2])\n",
    "  ax[0].set_ylabel(\"Input Current ($I_{in}$)\")\n",
    "  ax[0].set_title(\"Lapicque's Neuron Model With Step Input\")\n",
    "\n",
    "  # Plot membrane potential\n",
    "  ax[1].plot(mem_rec)\n",
    "  ax[1].set_ylim([0, 0.6]) \n",
    "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
    "\n",
    "  if vline1:\n",
    "    ax[1].axvline(x=vline1, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
    "  plt.xlabel(\"Time step\")\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_current_pulse_response(cur_in, mem_rec, title, vline1=False, vline2=False, ylim_max1=False):\n",
    "\n",
    "  fig, ax = plt.subplots(2, figsize=(8,6),sharex=True)\n",
    "\n",
    "  # Plot input current\n",
    "  ax[0].plot(cur_in, c=\"tab:orange\")\n",
    "  if not ylim_max1:\n",
    "    ax[0].set_ylim([0, 0.2])\n",
    "  else:\n",
    "    ax[0].set_ylim([0, ylim_max1])\n",
    "  ax[0].set_ylabel(\"Input Current ($I_{in}$)\")\n",
    "  ax[0].set_title(title)\n",
    "\n",
    "  # Plot membrane potential\n",
    "  ax[1].plot(mem_rec)\n",
    "  ax[1].set_ylim([0, 1])\n",
    "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
    "\n",
    "  if vline1:\n",
    "    ax[1].axvline(x=vline1, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
    "  if vline2:\n",
    "    ax[1].axvline(x=vline2, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
    "  plt.xlabel(\"Time step\")\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "def compare_plots(cur1, cur2, cur3, mem1, mem2, mem3, vline1, vline2, vline3, vline4, title):\n",
    "  # Generate Plots\n",
    "  fig, ax = plt.subplots(2, figsize=(8,6),sharex=True)\n",
    "\n",
    "  # Plot input current\n",
    "  ax[0].plot(cur1)\n",
    "  ax[0].plot(cur2)\n",
    "  ax[0].plot(cur3)\n",
    "  ax[0].set_ylim([0, 0.2])\n",
    "  ax[0].set_ylabel(\"Input Current ($I_{in}$)\")\n",
    "  ax[0].set_title(title)\n",
    "\n",
    "  # Plot membrane potential\n",
    "  ax[1].plot(mem1)\n",
    "  ax[1].plot(mem2)\n",
    "  ax[1].plot(mem3)\n",
    "  ax[1].set_ylim([0, 1])\n",
    "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
    "\n",
    "  ax[1].axvline(x=vline1, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
    "  ax[1].axvline(x=vline2, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
    "  ax[1].axvline(x=vline3, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
    "  ax[1].axvline(x=vline4, ymin=0, ymax=2.2, alpha = 0.25, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
    "\n",
    "  plt.xlabel(\"Time step\")\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "def plot_cur_mem_spk(cur, mem, spk, thr_line=False, vline=False, title=False, ylim_max2=1.25):\n",
    "  # Generate Plots\n",
    "  fig, ax = plt.subplots(3, figsize=(8,6), sharex=True, \n",
    "                        gridspec_kw = {'height_ratios': [1, 1, 0.4]})\n",
    "\n",
    "  # Plot input current\n",
    "  ax[0].plot(cur, c=\"tab:orange\")\n",
    "  ax[0].set_ylim([0, 0.4])\n",
    "  ax[0].set_xlim([0, 200])\n",
    "  ax[0].set_ylabel(\"Input Current ($I_{in}$)\")\n",
    "  if title:\n",
    "    ax[0].set_title(title)\n",
    "\n",
    "  # Plot membrane potential\n",
    "  ax[1].plot(mem)\n",
    "  ax[1].set_ylim([0, ylim_max2]) \n",
    "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
    "  if thr_line:\n",
    "    ax[1].axhline(y=thr_line, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
    "  plt.xlabel(\"Time step\")\n",
    "\n",
    "  # Plot output spike using spikeplot\n",
    "  splt.raster(spk, ax[2], s=400, c=\"black\", marker=\"|\")\n",
    "  if vline:\n",
    "    ax[2].axvline(x=vline, ymin=0, ymax=6.75, alpha = 0.15, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n",
    "  plt.ylabel(\"Output spikes\")\n",
    "  plt.yticks([]) \n",
    "\n",
    "  plt.show()\n",
    "\n",
    "def plot_spk_mem_spk(spk_in, mem, spk_out, title):\n",
    "  # Generate Plots\n",
    "  fig, ax = plt.subplots(3, figsize=(8,6), sharex=True, \n",
    "                        gridspec_kw = {'height_ratios': [0.4, 1, 0.4]})\n",
    "\n",
    "  # Plot input current\n",
    "  splt.raster(spk_in, ax[0], s=400, c=\"black\", marker=\"|\")\n",
    "  ax[0].set_ylabel(\"Input Spikes\")\n",
    "  ax[0].set_title(title)\n",
    "  plt.yticks([]) \n",
    "\n",
    "  # Plot membrane potential\n",
    "  ax[1].plot(mem)\n",
    "  ax[1].set_ylim([0, 1])\n",
    "  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
    "  ax[1].axhline(y=0.5, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
    "  plt.xlabel(\"Time step\")\n",
    "\n",
    "  # Plot output spike using spikeplot\n",
    "  splt.raster(spk_rec, ax[2], s=400, c=\"black\", marker=\"|\")\n",
    "  plt.ylabel(\"Output spikes\")\n",
    "  plt.yticks([]) \n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_reset_comparison(spk_in, mem_rec, spk_rec, mem_rec0, spk_rec0):\n",
    "  # Generate Plots to Compare Reset Mechanisms\n",
    "  fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(10,6), sharex=True, \n",
    "                        gridspec_kw = {'height_ratios': [0.4, 1, 0.4], 'wspace':0.05})\n",
    "\n",
    "  # Reset by Subtraction: input spikes\n",
    "  splt.raster(spk_in, ax[0][0], s=400, c=\"black\", marker=\"|\")\n",
    "  ax[0][0].set_ylabel(\"Input Spikes\")\n",
    "  ax[0][0].set_title(\"Reset by Subtraction\")\n",
    "  ax[0][0].set_yticks([])\n",
    "\n",
    "  # Reset by Subtraction: membrane potential \n",
    "  ax[1][0].plot(mem_rec)\n",
    "  ax[1][0].set_ylim([0, 0.7])\n",
    "  ax[1][0].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n",
    "  ax[1][0].axhline(y=0.5, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
    "\n",
    "  # Reset by Subtraction: output spikes\n",
    "  splt.raster(spk_rec, ax[2][0], s=400, c=\"black\", marker=\"|\")\n",
    "  ax[2][0].set_yticks([])\n",
    "  ax[2][0].set_xlabel(\"Time step\")\n",
    "  ax[2][0].set_ylabel(\"Output Spikes\")\n",
    "\n",
    "  # Reset to Zero: input spikes\n",
    "  splt.raster(spk_in, ax[0][1], s=400, c=\"black\", marker=\"|\")\n",
    "  ax[0][1].set_title(\"Reset to Zero\")\n",
    "  ax[0][1].set_yticks([])\n",
    "\n",
    "  # Reset to Zero: membrane potential\n",
    "  ax[1][1].plot(mem_rec0)\n",
    "  ax[1][1].set_ylim([0, 0.7])\n",
    "  ax[1][1].axhline(y=0.5, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n",
    "  ax[1][1].set_yticks([])\n",
    "  ax[2][1].set_xlabel(\"Time step\")\n",
    "\n",
    "  # Reset to Zero: output spikes\n",
    "  splt.raster(spk_rec0, ax[2][1], s=400, c=\"black\", marker=\"|\")\n",
    "  ax[2][1].set_yticks([])\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbdbca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((16, 16)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "# generate training and test data\n",
    "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
    "mnist_whole = datasets.MNIST(data_path, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bef97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train in batch sizes of x images\n",
    "batch_size = 128\n",
    "\n",
    "# configure device\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# create dataloader objects\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True\n",
    "                          , drop_last=True\n",
    "                         )\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True\n",
    "                         , drop_last=True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e41b315e-8d9c-4a85-91be-c3f0b16905e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Binarized model\n",
    "class Binarize(Function):\n",
    "  @staticmethod\n",
    "  def forward(weight_ref, input):\n",
    "    return input.sign().clamp(min=-1) # convert input to -1 or 1\n",
    "\n",
    "  @staticmethod\n",
    "  def backward(weight_ref, gradient_out):\n",
    "    gradient_in = gradient_out.clone() # create clone of weights for STE\n",
    "    return gradient_in\n",
    "\n",
    "class BinaryLinear(nn.Linear):\n",
    "    def forward(self, input):\n",
    "        bin_weights = Binarize.apply(self.weight)\n",
    "        if self.bias is None:\n",
    "            return F.linear(input, bin_weights)\n",
    "        else:\n",
    "            return F.linear(input, bin_weights, self.bias)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # Apply Xavier normal initialization\n",
    "        torch.nn.init.xavier_normal_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            # Initialize bias to zero\n",
    "            torch.nn.init.constant_(self.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0685b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "# number of pixels\n",
    "# num_inputs = 28*28\n",
    "num_inputs = 16*16\n",
    "# number of neurons in hidden layer\n",
    "num_hidden_1 = 150\n",
    "num_hidden_2 = 100\n",
    "num_hidden_3 = 50\n",
    "# output classes\n",
    "num_outputs = 10\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = 30\n",
    "beta = 1\n",
    "thresh = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c28a7e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = BinaryLinear(num_inputs, num_hidden_1)\n",
    "        self.lif1 = snn.Leaky(beta=beta\n",
    "                              # ,reset_mechanism=\"zero\"\n",
    "                              , threshold=thresh\n",
    "                             )\n",
    "        self.fc2 = BinaryLinear(num_hidden_1, num_hidden_2)\n",
    "        self.lif2 = snn.Leaky(beta=beta\n",
    "                              # ,reset_mechanism=\"zero\"\n",
    "                              , threshold=thresh\n",
    "                              )\n",
    "        self.fc3 = BinaryLinear(num_hidden_2, num_hidden_3)\n",
    "        self.lif3 = snn.Leaky(beta = beta\n",
    "                              #, reset_mechanism=\"zero\"\n",
    "                              , threshold = thresh\n",
    "                             )\n",
    "        self.fc4 = BinaryLinear(num_hidden_3, num_outputs)\n",
    "        self.lif4 = snn.Leaky(beta = beta\n",
    "                              #, reset_mechanism=\"zero\"\n",
    "                              , threshold = thresh\n",
    "                              )\n",
    "\n",
    "#         self.fc1 = BinaryLinear(num_inputs, num_outputs)\n",
    "#         self.lif1 = snn.Leaky(beta=beta\n",
    "#                               # ,reset_mechanism=\"zero\"\n",
    "#                               , threshold=thresh\n",
    "#                              )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        # mem1 = self.lif1.init_leaky()\n",
    "        # mem2 = self.lif2.init_leaky()\n",
    "        # mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        # # Record the final layer\n",
    "        # cur1_rec = []\n",
    "        # cur2_rec = []\n",
    "        # cur3_rec = []\n",
    "        \n",
    "        # spk1_rec = []\n",
    "        # mem1_rec = []\n",
    "        \n",
    "        # spk2_rec = []\n",
    "        # mem2_rec = []\n",
    "\n",
    "        # spk3_rec = []\n",
    "        # mem3_rec = []\n",
    "        \n",
    "        # for step in range(num_steps):\n",
    "        #     #cur1 = self.fc1(x[step])\n",
    "        #     cur1 = self.fc1(x)\n",
    "        #     cur1_rec.append(cur1)\n",
    "            \n",
    "        #     spk1, mem1 = self.lif1(cur1, mem1)\n",
    "        #     spk1_rec.append(spk1)\n",
    "        #     mem1_rec.append(mem1)\n",
    "            \n",
    "        #     cur2 = self.fc2(spk1)\n",
    "        #     cur2_rec.append(cur2)\n",
    "            \n",
    "        #     spk2, mem2 = self.lif2(cur2, mem2)\n",
    "        #     spk2_rec.append(spk2)\n",
    "        #     mem2_rec.append(mem2)\n",
    "\n",
    "        #     cur3 = self.fc3(spk2)\n",
    "        #     cur3_rec.append(cur3)\n",
    "\n",
    "        #     spk3, mem3 = self.lif3(cur3, mem3)\n",
    "        #     spk3_rec.append(spk3)\n",
    "        #     mem3_rec.append(mem3)\n",
    "\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        mem4 = self.lif4.init_leaky()\n",
    "\n",
    "        # # Record the layer\n",
    "        cur1_rec = []\n",
    "        spk1_rec = []\n",
    "        mem1_rec = []\n",
    "        \n",
    "        cur2_rec = []\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "        \n",
    "        cur3_rec = []\n",
    "        spk3_rec = []\n",
    "        mem3_rec = []\n",
    "        \n",
    "        cur4_rec = []\n",
    "        spk4_rec = []\n",
    "        mem4_rec = []\n",
    "        \n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            cur4 = self.fc4(spk3)\n",
    "            spk4, mem4 = self.lif4(cur4, mem4)\n",
    "            spk4_rec.append(spk4)\n",
    "            mem4_rec.append(mem4)\n",
    "            cur4_rec.append(cur4)\n",
    "            \n",
    "        \n",
    "        # spk2_rec = self.fc3(spk2)\n",
    "        # mem2_rec = self.lif2(cur3, mem3)\n",
    "        # return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0), \\\n",
    "        #        torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0), \\\n",
    "        #        torch.stack(spk1_rec, dim=0), torch.stack(mem1_rec, dim=0), \\\n",
    "        #        torch.stack(cur3_rec, dim=0), torch.stack(cur2_rec, dim=0), torch.stack(cur1_rec, dim=0)\n",
    "\n",
    "        return torch.stack(spk4_rec, dim=0), torch.stack(mem4_rec, dim=0), torch.stack(cur4_rec, dim=0)\n",
    "\n",
    "        # return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
    "        #return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    " \n",
    "        #return spk2_rec, mem2_rec\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b2936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Metrics:\n",
    "# pass data into the network, sum the spikes over time\n",
    "# and compare the neuron with the highest number of spikes\n",
    "# with the target\n",
    "\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    #batch_test_spiketrain = spikegen.rate(data.view(batch_size,-1), num_steps=num_steps)\n",
    "    batch_test_spiketrain = spikegen.rate(data.view(batch_size,-1), num_steps=1)\n",
    "    #print(batch_test_spiketrain.size())\n",
    "    batch_out = []\n",
    "#    for i in range(num_steps):\n",
    "    #batch_output, _, _, _, _, _, _, _, _ = net(batch_test_spiketrain)\n",
    "    # batch_output, _, _, _, _, _, _, _, _ = net(batch_test_spiketrain[0])\n",
    "    batch_output, _, _ = net(batch_test_spiketrain[0])\n",
    "    # batch_output, _ = net(batch_test_spiketrain[0])\n",
    "    #print(batch_output.size())\n",
    "    #output = torch.cat(batch_output, dim=1)\n",
    "    output = batch_output\n",
    "    #print(output.size())\n",
    "    _, idx = output.sum(dim=0).max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer(\n",
    "    data, targets, epoch,\n",
    "    counter, iter_counter,\n",
    "        loss_hist, test_loss_hist, test_data, test_targets):\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "588751fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# set up optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the SNN\n",
    "\n",
    "num_epochs = 10\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        # input_spiketrain = spikegen.rate(data.view(batch_size, -1), num_steps=num_steps)\n",
    "        input_spiketrain = spikegen.rate(data.view(batch_size, -1), num_steps=1)\n",
    "        spk_tot = []\n",
    "        mem_tot = []\n",
    "        #for i in range(num_steps):\n",
    "        #spk_slice, mem_slice, _, _, _, _, _, _, _ = net(input_spiketrain)\n",
    "        # spk_slice, mem_slice, _, _, _, _, _, _, _ = net(input_spiketrain[0])\n",
    "        spk_slice, mem_slice, _ = net(input_spiketrain[0])\n",
    "        # spk_slice, mem_slice = net(input_spiketrain[0])\n",
    "        #    spk_tot.append(spk_slice)\n",
    "        #    mem_tot.append(mem_slice)\n",
    "            \n",
    "        spk_rec = spk_slice\n",
    "        mem_rec = mem_slice\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            #test_t_spiketrain = spikegen.rate(test_data.view(batch_size,-1), num_steps=num_steps)\n",
    "            test_t_spiketrain = spikegen.rate(test_data.view(batch_size,-1), num_steps=1)\n",
    "            spk_test_tot = []\n",
    "            mem_test_tot = []\n",
    "            # for i in range(num_steps):\n",
    "            #  spk_tst, mem_tst, _, _, _, _, _, _, _ = net(test_t_spiketrain)\n",
    "            # spk_tst, mem_tst, _, _, _, _, _, _, _ = net(test_t_spiketrain[0])\n",
    "            \n",
    "            # spk_tst, mem_tst = net(test_t_spiketrain[0])\n",
    "            #    spk_test_tot.append(spk_tst)\n",
    "            #    mem_test_tot.append(mem_tst)\n",
    "            test_spk = spk_test_tot\n",
    "            test_mem = mem_test_tot\n",
    "\n",
    "            #test_spk, test_mem, _, _, _, _, _, _, _ = net(test_t_spiketrain)\n",
    "            # test_spk, test_mem, _, _, _, _, _, _, _ = net(test_t_spiketrain[0])\n",
    "            test_spk, test_mem, _ = net(test_t_spiketrain[0])\n",
    "            # test_spk, test_mem = net(test_t_spiketrain[0])\n",
    "            # Test set loss\n",
    "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "            for step in range(num_steps):\n",
    "                test_loss += loss(test_mem[step], test_targets)\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print train/test loss/accuracy\n",
    "            if counter % 50 == 0:\n",
    "                train_printer(\n",
    "                    data, targets, epoch,\n",
    "                    counter, iter_counter,\n",
    "                    loss_hist, test_loss_hist,\n",
    "                    test_data, test_targets)\n",
    "            counter += 1\n",
    "            iter_counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2a9a816-a218-4121-8738-734af3cf7534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test = snn.import_from_nir(nir_model)\n",
    "#print(test)\n",
    "#print(net)\n",
    "test = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af409e0-dfdb-4bf9-9248-f3e27159b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# drop_last switched to False to keep all samples\n",
    "test_loader = DataLoader(mnist_whole, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "m1_verif = []\n",
    "s1_verif = []\n",
    "\n",
    "m2_verif = []\n",
    "s2_verif = []\n",
    "\n",
    "m3_verif = []\n",
    "s3_verif = []\n",
    "\n",
    "i1_verif = []\n",
    "i2_verif = []\n",
    "i3_verif = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  test.eval()\n",
    "  for data, targets in test_loader:\n",
    "    data = data.to(device)\n",
    "    targets = targets.to(device)\n",
    "    \n",
    "    # forward pass\n",
    "    #test_spiketrain = spikegen.rate(data.view(batch_size, -1), num_steps=num_steps)\n",
    "    test_spiketrain = spikegen.rate(data.view(batch_size, -1), num_steps=1)\n",
    "    #test_spk3, test_mem3, test_spk2, test_mem2, test_spk1, test_mem1, test_i3, test_i2, test_i1  = test(test_spiketrain)\n",
    "    # test_spk3, test_mem3, test_spk2, test_mem2, test_spk1, test_mem1, test_i3, test_i2, test_i1  = test(test_spiketrain[0])\n",
    "    test_spk1, test_mem1, test_cur1 = test(test_spiketrain[0])\n",
    "    # test_spk3, test_mem3 = test(test_spiketrain[0])\n",
    "    \n",
    "#     m3_verif.append(test_mem3)\n",
    "#     s3_verif.append(test_spk3)\n",
    "      \n",
    "#     m2_verif.append(test_mem2)\n",
    "#     s2_verif.append(test_spk2)\n",
    "    \n",
    "    m1_verif.append(test_mem1)\n",
    "    s1_verif.append(test_spk1)\n",
    "    \n",
    "#     i3_verif.append(test_i3)\n",
    "#     i2_verif.append(test_i2)\n",
    "    i1_verif.append(test_cur1)\n",
    "      \n",
    "    # calculate total accuracy\n",
    "    # _, predicted = test_spk3.sum(dim=0).max(1)\n",
    "    _, predicted = test_spk1.sum(dim=0).max(1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets).sum().item()\n",
    "\n",
    "#membrane_pot = torch.stack(membrane_verif)\n",
    "#plot_mem(membrane_verif, \"Potential over timesteps\")\n",
    "\n",
    "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
    "print(f\"Test Set Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8dfd78-8853-4160-ad60-f5c2d3e5efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "disp_v = m2_verif[i]\n",
    "disp_spk = s2_verif[i]\n",
    "disp_inp = i2_verif[i]\n",
    "print(disp_inp[:,0,0])\n",
    "print(disp_v[:,0,0])\n",
    "print(disp_spk[:,0,0])\n",
    "plot_mem(disp_inp[:,0,0], ymin=-50, ymax=50, title=\"Input Current Plot\")\n",
    "plot_mem(disp_v[:,0,0], ymin=-75, ymax=175, title=\"Membrane Voltage Plot\")\n",
    "plot_mem(disp_spk[:,0,0], ymin=0, ymax=2, title=\"Spike Output Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de2bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = torch.randn(10, 50, 100, 150,  256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3bdf8-9200-4b7b-952d-1dbab9dfcf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nir_model = snn.export_to_nir(net, sample_data=sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d679fb98-9a52-49b6-8a6c-e5ea13a6c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nir_model.nodes:\n",
    "    if(str(i).startswith(\"fc\")):\n",
    "        ctr = 0;\n",
    "        for j in nir_model.nodes.get(i).weight:\n",
    "            nir_model.nodes.get(i).weight[ctr] = torch.Tensor.numpy(Binarize.forward(0, torch.from_numpy(j)))\n",
    "            ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449edb9-e395-4f4a-99b6-e8536772222f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(nir_model.nodes.get(\"fc1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909fe40e-183a-476b-b66e-462db87c83b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((nir_model.nodes.get(\"fc1\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e2ac4-6d26-4c4c-9d38-fcbb4d34ac03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((nir_model.nodes.get(\"fc2\").bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9384ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "nir.write(\"TEST5Layer.nir\", nir_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e60cccb-35b7-4da2-8cb5-5fffef226974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network\n",
    "class Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        # Initialize layers\n",
    "        self.fc1 = BinaryLinear(1, 1)\n",
    "        self.lif1 = snn.Leaky(beta=0.1\n",
    "                              , reset_mechanism=\"subtract\"\n",
    "                              , threshold=1.5\n",
    "                              , output=True\n",
    "                             )\n",
    "        self.fc2 = BinaryLinear(1, 1)\n",
    "        self.lif2 = snn.Leaky(beta=0.1\n",
    "                              , reset_mechanism=\"subtract\"\n",
    "                              , threshold=3\n",
    "                              , output=True\n",
    "                              )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        cur1_rec = []        \n",
    "        spk1_rec = []\n",
    "        mem1_rec = []\n",
    "\n",
    "        cur2_rec = []\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(50):\n",
    "            cur1 = self.fc1(x)\n",
    "            cur1_rec.append(cur1)\n",
    "            \n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            spk1_rec.append(spk1)\n",
    "            mem1_rec.append(mem1)\n",
    "            \n",
    "            cur2 = self.fc2(spk1)\n",
    "            cur2_rec.append(cur2)\n",
    "            \n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "            \n",
    "        #cur1 = self.fc1(x)\n",
    "        #spk1, mem1 = self.lif1(cur1, mem1)\n",
    "        #cur2 = self.fc2(spk1)\n",
    "        #spk2, mem2 = self.lif2(cur2, mem2)\n",
    "        #spk2_rec = spk2\n",
    "        #mem2_rec = mem2\n",
    "        \n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0), \\\n",
    "               torch.stack(spk1_rec, dim=0), torch.stack(mem1_rec, dim=0), \\\n",
    "               torch.stack(cur2_rec, dim=0), torch.stack(cur1_rec, dim=0)\n",
    "\n",
    "        # return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
    "        #return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    " \n",
    "        #return spk2_rec, mem2_rec\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "test_lif = Test().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc38d5e-cffd-4c43-80c9-87793aa5b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_lif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c318a3d2-a86c-4aa8-97e6-4d5f26e4a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  test_lif.eval()\n",
    "  test_in = torch.tensor([-1], dtype=torch.float)\n",
    "  test_lif_spk2, test_lif_mem2, test_lif_spk1, test_lif_mem1, test_lif_cur2, test_lif_cur1 = test_lif(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7bb9c-18e9-4f0a-9d1d-7ba0fc29cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_lif_cur1)\n",
    "print(test_lif_mem1)\n",
    "# print(test_lif_spk1)\n",
    "plot_mem(test_lif_cur1, ymin=-15,   ymax=15, xmax=50, title=\"Input Current Plot\")\n",
    "plot_mem(test_lif_mem1, ymin=-5, ymax=5, xmax=50, title=\"Membrane Voltage Plot\")\n",
    "plot_mem(test_lif_spk1, ymin=-0.5, ymax=2, xmax=50, title=\"Spike Output Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350cb4a-6ee5-422e-b166-93e641f81421",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mem(test_lif_cur2, ymin=-5, ymax=5, xmax=50, title=\"Input Current Plot\")\n",
    "plot_mem(test_lif_mem2, ymin=-5, ymax=5, xmax=50, title=\"Membrane Voltage Plot\")\n",
    "plot_mem(test_lif_spk2, ymin=-0.5, ymax=2, xmax=50, title=\"Spike Output Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d044e6-c48a-4d11-a8a7-193b37e5a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = snn.export_to_nir(test_lif, sample_data=test_in)\n",
    "print(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1bfa44-e79e-4fc5-a9fc-4c8c5051bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Affine(\n",
    "    weight=array([[ 1.,  1., -1., ..., -1., -1.,  1.],\n",
    "       [ 1.,  1., -1., ..., -1., -1., -1.],\n",
    "       [-1.,  1.,  1., ..., -1.,  1.,  1.],\n",
    "       ...,\n",
    "       [-1., -1., -1., ..., -1., -1.,  1.],\n",
    "       [ 1.,  1., -1., ..., -1.,  1., -1.],\n",
    "       [-1., -1., -1., ...,  1., -1.,  1.]], dtype=float32),\n",
    "    bias=array([ 0.1009215 ,  0.01056621,  0.04929107, -0.0332957 , -0.03695581,\n",
    "        0.03904731,  0.0197216 , -0.07571533,  0.05091662,  0.08878961,\n",
    "        0.01564536,  0.05161016,  0.06772061,  0.0632091 ,  0.02623171,\n",
    "       -0.05013173,  0.02469478,  0.0404999 ,  0.08496135,  0.01402613,\n",
    "        0.07954828,  0.03962149,  0.04144652, -0.07856443,  0.02252836,\n",
    "        0.01329264, -0.02184459, -0.01157423,  0.05655716,  0.04655876,\n",
    "        0.02352429,  0.06137991,  0.06815517,  0.01155421,  0.01147448,\n",
    "        0.03722914,  0.04600598, -0.0073339 ,  0.04141028,  0.00146396,\n",
    "       -0.0383213 ,  0.02292555, -0.00051601, -0.02771499, -0.03703493,\n",
    "        0.04732281,  0.00766984, -0.05779942,  0.02206175,  0.03283292,\n",
    "        0.05404404,  0.05544268, -0.03703262,  0.02228428,  0.12030443,\n",
    "        0.00716768,  0.03350221, -0.03384176,  0.07111918,  0.06375866,\n",
    "        0.06401234,  0.01839542,  0.04442194,  0.05609976,  0.01979149,\n",
    "        0.03706134, -0.01640035, -0.04544761,  0.05218566,  0.11039118,\n",
    "       -0.00209426,  0.04198991,  0.10689857,  0.09557332,  0.09015911,\n",
    "        0.0064611 , -0.0013184 ,  0.0154663 ,  0.0777692 ,  0.02402217,\n",
    "        0.0268336 ,  0.01880237,  0.03845166,  0.05565656,  0.08355922,\n",
    "       -0.06279235,  0.03985051, -0.03999543,  0.03747547,  0.07245038,\n",
    "        0.00344533,  0.014121  , -0.00683245,  0.06389244,  0.0659066 ,\n",
    "        0.03508978,  0.0443225 ,  0.09641098, -0.08349199, -0.04515573,\n",
    "        0.06336527,  0.0041139 , -0.01503064, -0.00505937, -0.02682389,\n",
    "        0.08607724,  0.06691478, -0.08266222,  0.03992905,  0.10163339,\n",
    "       -0.00770793,  0.07837504,  0.02225685,  0.05250541,  0.08909381,\n",
    "        0.02886833, -0.03612163, -0.01325568,  0.05510648,  0.00239697,\n",
    "        0.05198224, -0.02760084,  0.02568853, -0.01226529, -0.01560187,\n",
    "       -0.02417283, -0.04900137, -0.06605668,  0.05759297, -0.04377581,\n",
    "       -0.05016879, -0.07030804,  0.0689007 ,  0.008381  ,  0.01178456,\n",
    "       -0.02010161,  0.05507733, -0.01015529,  0.00208677,  0.0359959 ,\n",
    "        0.01760789,  0.03947135, -0.00360024, -0.07412802, -0.01526334,\n",
    "       -0.01073579, -0.05350151, -0.00946829, -0.04080444, -0.08862601,\n",
    "       -0.01905126,  0.02373825,  0.02561951,  0.01501931, -0.00516778,\n",
    "        0.02493444,  0.05075564, -0.01322739, -0.02902855, -0.1127844 ,\n",
    "       -0.00602325, -0.03932552,  0.00220306, -0.00974231,  0.06671224,\n",
    "       -0.01214928,  0.01339486,  0.06013608, -0.0531178 ,  0.04542631,\n",
    "        0.03016868, -0.04219029,  0.07481925,  0.0727564 , -0.01565988,\n",
    "       -0.01174347, -0.06760536, -0.00660002,  0.06531591, -0.01187729,\n",
    "        0.04688989, -0.05211253, -0.06112675,  0.00553037,  0.05430356,\n",
    "        0.02847206,  0.12328246, -0.01823531,  0.09615794, -0.05857543,\n",
    "        0.04499691,  0.04760434,  0.05337632,  0.06946445, -0.03134006,\n",
    "        0.0313275 ,  0.03067483,  0.01288446, -0.03583638,  0.05112115,\n",
    "        0.05633372, -0.04109506, -0.06682277,  0.1041477 ,  0.03991095,\n",
    "       -0.04537598,  0.06061276, -0.01500979,  0.01395738,  0.10575601,\n",
    "        0.02338696, -0.05161939, -0.01893329,  0.05781336,  0.02891826,\n",
    "       -0.03324988,  0.07301032, -0.07468474, -0.07354445,  0.03644063,\n",
    "       -0.03213177,  0.02539858,  0.08209603,  0.02195088, -0.01625294,\n",
    "        0.01847285, -0.00574548, -0.0283527 ,  0.06356864,  0.07001008,\n",
    "       -0.04465934,  0.02699364,  0.01516743,  0.03485133,  0.05516924,\n",
    "        0.01876684,  0.04320775,  0.0415695 ,  0.08099367,  0.11294322,\n",
    "        0.07247799,  0.06351856, -0.01124045,  0.10493372,  0.00753347,\n",
    "       -0.03757563,  0.0159433 , -0.0439716 , -0.08869992,  0.03093558,\n",
    "       -0.05897093,  0.02038252,  0.0390482 ,  0.01463429, -0.05734879,\n",
    "        0.07094757], dtype=float32), input_type={'input': array([784])}, output_type={'output': array([256])}, metadata={})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
